{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import glob\n",
    "from itertools import chain\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Art</td>\n",
       "      <td>This article is about the academic discipline ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Art_history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Art</td>\n",
       "      <td>If you're seeing this message, it means we're ...</td>\n",
       "      <td>https://www.khanacademy.org/humanities/art-his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Art</td>\n",
       "      <td>If you're seeing this message, it means we're ...</td>\n",
       "      <td>https://www.khanacademy.org/humanities/art-his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Art</td>\n",
       "      <td>Art history, also called art historiography, h...</td>\n",
       "      <td>https://www.britannica.com/art/art-history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Art</td>\n",
       "      <td>\"Why study art history when there are many oth...</td>\n",
       "      <td>https://www.iesa.edu/paris/news-events/art-his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Art</td>\n",
       "      <td>The Definition of Islamic Art\\n\\nThe objective...</td>\n",
       "      <td>https://apcentral.collegeboard.org/courses/ap-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Art</td>\n",
       "      <td>Building a Context\\n\\nArchitecture can be a ch...</td>\n",
       "      <td>https://apcentral.collegeboard.org/courses/ap-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Art</td>\n",
       "      <td>The art of Africa covers a broad region, of co...</td>\n",
       "      <td>http://www.arthistory.net/african-art/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  \\\n",
       "0   Art  This article is about the academic discipline ...   \n",
       "1   Art  If you're seeing this message, it means we're ...   \n",
       "2   Art  If you're seeing this message, it means we're ...   \n",
       "3   Art  Art history, also called art historiography, h...   \n",
       "4   Art  \"Why study art history when there are many oth...   \n",
       "5   Art  The Definition of Islamic Art\\n\\nThe objective...   \n",
       "6   Art  Building a Context\\n\\nArchitecture can be a ch...   \n",
       "7   Art  The art of Africa covers a broad region, of co...   \n",
       "\n",
       "                                                 url  \n",
       "0          https://en.wikipedia.org/wiki/Art_history  \n",
       "1  https://www.khanacademy.org/humanities/art-his...  \n",
       "2  https://www.khanacademy.org/humanities/art-his...  \n",
       "3         https://www.britannica.com/art/art-history  \n",
       "4  https://www.iesa.edu/paris/news-events/art-his...  \n",
       "5  https://apcentral.collegeboard.org/courses/ap-...  \n",
       "6  https://apcentral.collegeboard.org/courses/ap-...  \n",
       "7             http://www.arthistory.net/african-art/  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = open(\"articledata.json\")\n",
    "d = json.load(fp)\n",
    "l = []\n",
    "for url in d.keys():\n",
    "    x = {'text': d[url]}\n",
    "    if d[url]:\n",
    "        x['url'] = url\n",
    "        x['label'] = 'Art'\n",
    "        l.append(x)\n",
    "df = pd.DataFrame(l)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for f in df['text']:\n",
    "    words.append(f)\n",
    "\n",
    "words = list(chain.from_iterable(words))\n",
    "words = ''.join(words)[:-1]\n",
    "sentences = words.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words (+UNK) [['UNK', 142], ('the', 561), ('of', 474), ('and', 335), ('to', 216)]\n",
      "Sample data [[45, 552, 8, 59, 1, 364, 124, 2, 6, 172, 73, 16, 553, 2, 1, 13, 2, 6, 1078, 365, 52, 2, 6, 35, 73, 60, 1079, 365, 21, 13, 0], []]\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 40000\n",
    "\n",
    "def build_dataset(sentences):\n",
    "    words = ''.join(sentences).split()\n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(collections.Counter(words).most_common(vocabulary_size - 1))\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    \n",
    "    unk_count = 0\n",
    "    sent_data = []\n",
    "    for sentence in sentences:\n",
    "        data = []\n",
    "        for word in sentence.split():\n",
    "            if word in dictionary:\n",
    "                index = dictionary[word]\n",
    "            else:\n",
    "                index = 0  # dictionary['UNK']\n",
    "                unk_count = unk_count + 1\n",
    "            data.append(index)\n",
    "        sent_data.append(data)\n",
    "    \n",
    "    count[0][1] = unk_count\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys())) \n",
    "    return sent_data, count, dictionary, reverse_dictionary\n",
    "\n",
    "data, count, dictionary, reverse_dictionary = build_dataset(sentences)\n",
    "print('Most common words (+UNK)', count[:5])\n",
    "print('Sample data', data[:2])\n",
    "# del words  # Hint to reduce memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10098\n"
     ]
    }
   ],
   "source": [
    "skip_window = 3\n",
    "instances = 0\n",
    "\n",
    "# Pad sentence with skip_windows\n",
    "for i in range(len(data)):\n",
    "    data[i] = [vocabulary_size]*skip_window+data[i]+[vocabulary_size]*skip_window\n",
    "\n",
    "# Check how many training samples that we get    \n",
    "for sentence  in data:\n",
    "    instances += len(sentence)-2*skip_window\n",
    "print(instances)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_len = np.array([len(d) for d in data])\n",
    "plt.hist(sent_len,100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = np.zeros((instances,skip_window*2+1),dtype=np.int32)\n",
    "labels = np.zeros((instances,1),dtype=np.int32)\n",
    "doc = np.zeros((instances,1),dtype=np.int32)\n",
    "\n",
    "k = 0\n",
    "for doc_id, sentence  in enumerate(data):\n",
    "    for i in range(skip_window, len(sentence)-skip_window):\n",
    "#         buffer = sentence[i-skip_window:i+skip_window+1]\n",
    "#         labels[k] = sentence[i]\n",
    "#         del buffer[skip_window]\n",
    "#         context[k] = buffer\n",
    "#         doc[k] = doc_id\n",
    "#         k += 1\n",
    "        context[k] = sentence[i-skip_window:i+skip_window+1] # Get surrounding words\n",
    "        labels[k] = sentence[i] # Get target variable\n",
    "        doc[k] = doc_id\n",
    "        k += 1\n",
    "        \n",
    "context = np.delete(context,skip_window,1) # delete the middle word        \n",
    "        \n",
    "shuffle_idx = np.random.permutation(k)\n",
    "labels = labels[shuffle_idx]\n",
    "doc = doc[shuffle_idx]\n",
    "context = context[shuffle_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0814 19:29:54.971312 4621100480 deprecation.py:323] From /Users/peach/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0814 19:29:55.141247 4621100480 deprecation.py:506] From /Users/peach/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0814 19:29:55.173512 4621100480 deprecation.py:506] From <ipython-input-14-e83d95f4a36b>:41: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "context_window = 2*skip_window\n",
    "embedding_size = 50 # Dimension of the embedding vector.\n",
    "softmax_width = embedding_size # +embedding_size2+embedding_size3\n",
    "num_sampled = 5 # Number of negative examples to sample.\n",
    "sum_ids = np.repeat(np.arange(batch_size),context_window)\n",
    "\n",
    "len_docs = len(data)\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default(): # , tf.device('/cpu:0')\n",
    "    # Input data.\n",
    "    train_word_dataset = tf.placeholder(tf.int32, shape=[batch_size*context_window])\n",
    "    train_doc_dataset = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "\n",
    "    segment_ids = tf.constant(sum_ids, dtype=tf.int32)\n",
    "\n",
    "    word_embeddings = tf.Variable(tf.random_uniform([vocabulary_size,embedding_size],-1.0,1.0))\n",
    "    word_embeddings = tf.concat([word_embeddings,tf.zeros((1,embedding_size))],0)\n",
    "    doc_embeddings = tf.Variable(tf.random_uniform([len_docs,embedding_size],-1.0,1.0))\n",
    "\n",
    "    softmax_weights = tf.Variable(tf.truncated_normal([vocabulary_size, softmax_width],\n",
    "                             stddev=1.0 / np.sqrt(embedding_size)))\n",
    "    softmax_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "    # Model.\n",
    "    # Look up embeddings for inputs.\n",
    "    embed_words = tf.segment_mean(tf.nn.embedding_lookup(word_embeddings, train_word_dataset),segment_ids)\n",
    "    embed_docs = tf.nn.embedding_lookup(doc_embeddings, train_doc_dataset)\n",
    "    embed = (embed_words+embed_docs)/2.0#+embed_hash+embed_users\n",
    "\n",
    "    # Compute the softmax loss, using a sample of the negative labels each time.\n",
    "    loss = tf.reduce_mean(tf.nn.nce_loss(softmax_weights, softmax_biases, train_labels, \n",
    "                                         embed, num_sampled, vocabulary_size))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.AdagradOptimizer(0.5).minimize(loss)\n",
    "        \n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(doc_embeddings), 1, keep_dims=True))\n",
    "    normalized_doc_embeddings = doc_embeddings / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################\n",
    "# Chunk the data to be passed into the tensorflow Model\n",
    "###########################\n",
    "data_idx = 0\n",
    "def generate_batch(batch_size):\n",
    "    global data_idx\n",
    "\n",
    "    if data_idx+batch_size<instances:\n",
    "        batch_labels = labels[data_idx:data_idx+batch_size]\n",
    "        batch_doc_data = doc[data_idx:data_idx+batch_size]\n",
    "        batch_word_data = context[data_idx:data_idx+batch_size]\n",
    "        data_idx += batch_size\n",
    "    else:\n",
    "        overlay = batch_size - (instances-data_idx)\n",
    "        batch_labels = np.vstack([labels[data_idx:instances],labels[:overlay]])\n",
    "        batch_doc_data = np.vstack([doc[data_idx:instances],doc[:overlay]])\n",
    "        batch_word_data = np.vstack([context[data_idx:instances],context[:overlay]])\n",
    "        data_idx = overlay\n",
    "    batch_word_data = np.reshape(batch_word_data,(-1,1))\n",
    "\n",
    "    return batch_labels, batch_word_data, batch_doc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Average loss at step 0: 31.925512\n",
      "Average loss at step 50000: 6.710767\n",
      "Average loss at step 100000: 1.757895\n",
      "Average loss at step 150000: 0.768172\n",
      "Average loss at step 200000: 0.418239\n",
      "Average loss at step 250000: 0.273582\n",
      "Average loss at step 300000: 0.213424\n",
      "Average loss at step 350000: 0.175148\n",
      "Average loss at step 400000: 0.162720\n",
      "Average loss at step 450000: 0.151914\n",
      "Average loss at step 500000: 0.144472\n",
      "Average loss at step 550000: 0.139787\n",
      "Average loss at step 600000: 0.136614\n",
      "Average loss at step 650000: 0.135240\n",
      "Average loss at step 700000: 0.133735\n",
      "Average loss at step 750000: 0.132198\n",
      "Average loss at step 800000: 0.131389\n",
      "Average loss at step 850000: 0.129497\n",
      "Average loss at step 900000: 0.129535\n",
      "Average loss at step 950000: 0.128046\n",
      "Average loss at step 1000000: 0.127810\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1000001\n",
    "step_delta = int(num_steps/20)\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    average_loss = 0\n",
    "    for step in range(num_steps):\n",
    "        batch_labels, batch_word_data, batch_doc_data\\\n",
    "        = generate_batch(batch_size)\n",
    "        feed_dict = {train_word_dataset : np.squeeze(batch_word_data),\n",
    "                     train_doc_dataset : np.squeeze(batch_doc_data),\n",
    "                     train_labels : batch_labels}\n",
    "        _, l = session.run([optimizer, loss], feed_dict=feed_dict)\n",
    "        average_loss += l\n",
    "        if step % step_delta == 0:\n",
    "            if step > 0:\n",
    "                average_loss = average_loss / step_delta\n",
    "            # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "            print('Average loss at step %d: %f' % (step, average_loss))\n",
    "            average_loss = 0\n",
    "\n",
    "    # Get the weights to save for later\n",
    "#     final_doc_embeddings = normalized_doc_embeddings.eval()\n",
    "    final_word_embeddings = word_embeddings.eval()\n",
    "    final_word_embeddings_out = softmax_weights.eval()\n",
    "    final_doc_embeddings = normalized_doc_embeddings.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999998\n",
      "0.31199187\n",
      "0.28531286\n",
      "0.2788008\n",
      "-0.48411837\n"
     ]
    }
   ],
   "source": [
    "rand_doc = np.random.randint(len_docs)\n",
    "dist = final_doc_embeddings.dot(final_doc_embeddings[rand_doc][:,None])\n",
    "closest_doc = np.argsort(dist,axis=0)[-4:][::-1]\n",
    "furthest_doc = np.argsort(dist,axis=0)[0][::-1]\n",
    "\n",
    "for idx in closest_doc:\n",
    "    print(dist[idx][0][0])\n",
    "    \n",
    "print(dist[furthest_doc][0][0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dist,100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[rand_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'African art has its origins in pre-history. Some rock art recently discovered in South Africa near the Cape may be older than 70,000 years old. The continent is home to a large body of prehistoric rock art. Traditional African art is comprised of art forms such as masks, jewelry, carvings, rock art, sculpture, textiles, metalwork, and much more. Many nations are associated with particular art forms. For example, various peoples of Mali and Cote d’Ivoire are renowned for their traditional masks and headdresses. Tanzania’s Makonde art of fine carving continues to be revered today.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[closest_doc[1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Studying art history is really not about memorizing dates, artists’ names, art movements, etc. Instead, it drives you to analyze paintings, photographs, sculptures, etc. To support your analysis, you must build rational and convincing arguments, hence developing your critical thinking.The Definition of Islamic Art'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[closest_doc[2][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Art history is not only a biographical endeavor. Art historians often root their studies in the scrutiny of individual objects. They thus attempt to answer in historically specific ways, questions such as: What are key features of this style?, What meaning did this object convey?, How does it function visually?, Did the artist meet their goals well?, What symbols are involved?, and Does it function discursively?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[closest_doc[3][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[furthest_doc[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'norm_vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-e0d4473586e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnorm_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_doc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclosest_doc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'norm_vec' is not defined"
     ]
    }
   ],
   "source": [
    "norm_vec[rand_doc].dot(norm_vec[closest_doc[1][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(dist,100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "cpus = cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_corpus():\n",
    "    for i,sentence in enumerate(words.split('\\n')):\n",
    "        yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(sentence), [i])\n",
    "\n",
    "train_corpus = list(read_corpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peach/miniconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py:576: UserWarning: The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\n",
      "  warnings.warn(\"The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\")\n",
      "/Users/peach/miniconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py:580: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "W0814 21:07:43.892540 4621100480 base_any2vec.py:723] consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec(dm=1, dm_concat=0, size=embedding_size, window=skip_window, \n",
    "                negative=5,hs=0, min_count=5, workers=cpus, iter=2)\n",
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You must specify either total_examples or total_words, for proper job parameters updationand progress calculations. The usual value is total_examples=model.corpus_count.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, documents, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[1;32m    804\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             queue_factor=queue_factor, report_delay=report_delay, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             total_words=total_words, **kwargs)\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_check_training_sanity\u001b[0;34m(self, epochs, total_examples, total_words, **kwargs)\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_words\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtotal_examples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m             raise ValueError(\n\u001b[0;32m-> 1200\u001b[0;31m                 \u001b[0;34m\"You must specify either total_examples or total_words, for proper job parameters updation\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m                 \u001b[0;34m\"and progress calculations. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0;34m\"The usual value is total_examples=model.corpus_count.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You must specify either total_examples or total_words, for proper job parameters updationand progress calculations. The usual value is total_examples=model.corpus_count."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.train(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8846234083175659\n",
      "0.8725295066833496\n",
      "0.8673354387283325\n"
     ]
    }
   ],
   "source": [
    "closest_doc2 = model.docvecs.most_similar([model.docvecs[rand_doc]],topn=4)\n",
    "for _, sim in closest_doc2:\n",
    "    print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'peter crawford discovers a comet on a collision course with the moon but when the government doesn t believe him dumb fact he builds a shelter in deep underground and is drawing lots to see who will go plus is willing to kill to save humanity dumb fact with millions of dollars of technology how could a civilian see what nasa could not plus the ends justifies the means moral of this story is just plain wrong this movie is improbable and totally unbelievable what was running through these people minds why the hell do crap piles like this get the green light some times i wonder who someone has to to get a movie made in this ing town '"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[rand_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the title of this documentary is very misleading at no time during the documentary do they show how the introduction of the nile perch fish into lake victoria has cause any of the problems facing the town of mwanza tanzania the film tries to place the problems of tanzania on an environmental cause but the truth of that matter is the problems stem from a parasitic outside force the documentary is very slowing paced with no narrative what so ever instead it relies on small blips of text between none related segments to display bits of information that do little to add or expand of the subject matter there are only two attempts to discus the environmental effects of the nile perch fish one is a small segment about seconds long where they interview the factory managers where the fish is processed and he briefly mentions how years ago the nile perch was introduced into the lake and it consumed the other fish species the film maker makes no attempt to follow up on the matter or go deeper into it the second attempt is when within this documentary they film the showing of another documentary that is discussing the environmental impact the nile perch has introduced and again no real attempt is made to expand on just how devastating the problem has become the subject matter that this documentary does delve into has nothing to do with the perch fish itself and more to do with the problems facing most african countries the film tries to link the introduction of the perch fish with aids poverty and pollution in tanzania but never makes a direct connection as any intelligent person well read with problems in africa the problems shown here are not unique to tanzania but affect most of africa and have nothing to do with the fish it would have been great if the film makers would have shown how the local economy or life was before the fish was introduced and how it has been negatively impacted by the introduction of the fish but they don t the fact of the matter is that many of the people they interview say that the fish has provided jobs and opportunity for many yes things are bad within the town of mwanza but they are far worst in other parts of the country and continent for that matter a weak attempt by the documentary makers to link the fish to famine problems in tanzania is quickly discredited by the documentary itself first off tanzania is a very large country and lake victoria is only a small portion of the country many of the individuals interview actually say that they can to mwanza the fishing town on the lake to find a job and feed their families because things were so bad in other parts of the country this documentary is very weak has no narrative and makes no attempt to actually link anything they display to the nile perch it plays on people s emotions by displaying images of the devastation of poverty famine and aids making no attempt to show you how any of this is unique to the lake victoria region of tanzania or directly related to the perch fish the fact is most of the problems have more to do with war globalization and christianity than and environmental effect of the perch fish itself '"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[closest_doc2[1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this could have been great the voice overs are exactly right and fit the characters to a t one small problem though the look of the characters mostly the supporting or guest characters look exactly the same the same bored look on every face only with minor changes such as hairlines or weight size it looks kind of odd to see a really big guest star s voice coming out of a lifeless form like the characters here if i am not mistaken kathy griffin did a voice over for this show and it looked too odd to be funny there is a few other problems one being the family plot the simpsons did it much better where you could actually buy most of the situations the characters got themselves into here we get too much annoying diversions like someone having a weird fantasy and then we are supposed to find that funny but for some reason the delivery is a bit off as you can probably tell it is hard for me to put a finger on exactly what is wrong with this show because it basically nothing more than a clone of the simpsons or even more married with children if i should point a finger on what is totally wrong with this it probably is it s repetitiveness peter griffin is not really a bright character but neither are any of the others lois should have been named lois lame because she is sort of one dimensional seth green as the kind of retarded son is the best thing about this show and that is the most stereotypical part on the show so what more can i say there isn t exactly anything wrong with this show but in the long run you have to admit that it takes a lot of work to do what the simpsons has done for almost two decades '"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[closest_doc2[2][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i like many folks believe the epic lonesome dove was one of the best westerns ever produced maybe the best and realizing that most sequels in this case a prequel are certain to disappoint my expectations were low comanche moon met that expectation with its marginal directing and acting poor casting and frankly a lousy script lonesome dove created western heroes of captains mccrae and call due to incredibly strong performances by robert duvall and tommy lee jones prior to living in lonesome dove we believed they bravely fought to rid texas of bandits and savage indians during their rangering years if i had only seen comanche moon i would think these two boneheads were a couple of incompetent cowardly idiots in lonesome dove call and mccrae supposedly chased blue duck all over texas and never managed to capture or kill him in comanche moon a shot to call s boot heel convinced him to settle down and raise cattle there wasn t a decent fistfight or gun fight in the entire miniseries the best punch was mccrea sucker punching inez scull a funny scene but out of character for mccrae where was mccrae s wit and charm clara s love for mccrae a drunken unshaven slob and philanderer was completely implausible and maggie s love for call a dispassionate and sullen loner defies logic the cinematography was excellent superior to the original credit goes not only to hd technology but the cinematographer the comanche moon miniseries was better than anything else on tv for three nights but sadly that s not saying much '"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[closest_doc2[3][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 50)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"tag '311' not seen in training corpus/invalid\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-d56c22a76f18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnorm_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvec\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnorm_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm_vec\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnorm_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_doc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclosest_doc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-d56c22a76f18>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnorm_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvec\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnorm_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm_vec\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnorm_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_doc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclosest_doc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m   1576\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_int_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoctags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_rawint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1577\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1578\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tag '%s' not seen in training corpus/invalid\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"tag '311' not seen in training corpus/invalid\""
     ]
    }
   ],
   "source": [
    "norm_vec = np.array([vec for vec in model.docvecs])\n",
    "norm_vec = norm_vec/np.sqrt(np.sum(np.square(norm_vec),axis=1,keepdims=True))\n",
    "\n",
    "norm_vec[rand_doc].dot(norm_vec[closest_doc[1][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
